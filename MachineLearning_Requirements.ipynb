{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](logo.png)\n",
    "\n",
    "\n",
    "# AI LAB Tikal Tech\n",
    "This is a Jupyter Notebook containg some exercises to test the skill requirements for being part of our AI LAB here at Tikal Tech.\n",
    "\n",
    "### Purpose\n",
    "The purpose of these exercises are twofold: \n",
    "* First, it is supposed to be used as a self-assessment tool. By solving the exercises, you can check if you have the necessary skills to be able to follow what comes next in your learning path here at Tikal Lab\n",
    "\n",
    "* The second purpose is to understand how you deal with deliveries in a short time frame.\n",
    "\n",
    "### Python\n",
    "Please, use Python 3.x while solving the exercises. If you are using Windows or macOS and you still don't have python installed, we recommend [Anaconda](https://www.continuum.io/downloads) - a Data Science focused python distribution. If you are using Linux, your package manager will be enough to install a Python 3.x distribution - but you still can use Anaconda if you prefer.\n",
    "\n",
    "You may use python modules to solve the exercises if you like, but they must be available in the default Anaconda installation or in PyPi (the Python Package Index).\n",
    "\n",
    "### Tools\n",
    "This is a Jupyter Notebook. If you never used one, a Jupyter notebook is a mix of Markdown (like a Wiki) and a Python program. It is used heavily by people working with Data Science and Machine Learning in Python. You can mix Markdown text and live program logic - which is a good combination. You can solve a problem and, at the same time, explain what your doing to solve it. If you need some help on how to use Jupyter Notebooks, please take a look at this [tutorial](https://www.datacamp.com/community/tutorials/tutorial-jupyter-notebook).\n",
    "\n",
    "You are free to add as many cells as you want to this notebook in order to make your work readable and well organized.\n",
    "\n",
    "\n",
    "### Scope\n",
    "The exercises cover two sets of skills: basic and advanced. \n",
    "\n",
    "The basic ones are not difficult to solve and even if you don't know python, it will be simple enough if you take the time to learn the basics of the language. However, they are flexible enough so you can show your skills if you are a more advanced programmer.\n",
    "\n",
    "We encourage you to also take a shot at the advanced exercises. They are not mandatory, but if you are able to solve them, it is certain that you will be able to make the most of the training.\n",
    "\n",
    "### Solutions for the exercices\n",
    "The goal here is not about getting the answers right or wrong. The goal is to evaluate how you solve the problems and how familiar you are with the concepts. So, take the time to write good code and explain yourself. It is better to be understood than to have the right answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Exercises\n",
    "Let's begin! Start by printing your name and e-mail here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in your data\n",
    "print('My name is ...')\n",
    "print('My email is ...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Leap Years and the Gregorian Calendar\n",
    "According to the current calendar used in the Western Countries, there is a rule to say if a given year is a [leap year](https://en.wikipedia.org/wiki/Gregorian_calendar) (ano bissexto) or not. The basic rule is the following:\n",
    "1. There is an additional day (February 29th) every 4 years. So, 2016, 2020, 2024 and so on are leap years\n",
    "2. The rule (1) does not apply every 100 years. So, 1900 was not a leap year and 2100 will not be a leap year\n",
    "3. The rule (2) does not apply every 400 years. So, 2000 was a leap year and 2400 will also be a leap year\n",
    "\n",
    "\n",
    "#### 1.1 Write a function that receives an year as an argument and returnes True if the year is a Leap year and False otherwise. Consider that this function must work for every year >= 1583 (the Gregorian Calendar was established on 1582).\n",
    "\n",
    "Some initial code is already written for your. Please, complete it.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_leap_year(year):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #your code here\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing your code\n",
    "print(\"Was 2016 a leap year? {} (should be True)\".format(is_leap_year(2016)))\n",
    "print(\"Will 2020 be a leap year? {} (should be True)\".format(is_leap_year(2020)))\n",
    "print(\"Will 2100 be a leap year? {} (should be False)\".format(is_leap_year(2100)))\n",
    "print(\"Was 2000 a leap year? {} (should be True)\".format(is_leap_year(2000)))\n",
    "print(\"Was 1997 a leap year? {} (should be False)\".format(is_leap_year(1997)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Finally, create a function that calculate how many leap years exists between 2 dates (end date inclusive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_leap_years(start_year, end_year):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #your code here\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing your code\n",
    "ly_count = count_leap_years(1973, 2017)\n",
    "print(\"The number of leap years between 1973 and 2017 are : {} (should be 11)\".format(ly_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyzing Beatles Lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a Beatles song - Hey Jude. These are the sentences of the song that we will use during this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hey_jude = [[\"Hey\", \"Jude\" , \"don't\",  \"make\",  \"it\",  \"bad\"],\n",
    "            [\"Take\",  \"a\",  \"sad\",  \"song\",  \"and\", \"make\",  \"it\",  \"better\"],\n",
    "            [\"Remember\", \"to\", \"let\", \"her\", \"into\", \"your\", \"heart\"],\n",
    "            [\"Then\", \"you\", \"can\", \"start\", \"to\", \"make\", \"it\", \"better\"],\n",
    "            [\"Hey\", \"Jude\", \"don't\", \"be\", \"afraid\"],\n",
    "            [\"You\", \"were\", \"made\", \"to\", \"go\", \"out\", \"and\", \"get\", \"her\"],\n",
    "            [\"The\", \"minute\", \"you\", \"let\", \"her\", \"under\", \"your\", \"skin\"],\n",
    "            [\"Then\", \"you\", \"begin\", \"to\", \"make\", \"it\", \"better\"],\n",
    "            [\"And\", \"anytime\", \"you\", \"feel\", \"the\", \"pain\", \"hey\",\"Jude\", \"refrain\"],\n",
    "            [\"Don't\", \"carry\", \"the\", \"world\", \"upon\", \"your\", \"shoulders\"],\n",
    "            [\"For\", \"well\", \"you\", \"know\", \"that\", \"it's\", \"a\", \"fool\", \"who\", \"plays\", \"it\", \"cool\"],\n",
    "            [\"By\", \"making\", \"his\", \"world\", \"a\", \"little\", \"colder\"],\n",
    "            [\"Hey\", \"Jude\", \"don't\", \"let\", \"me\", \"down\"],\n",
    "            [\"You\", \"have\", \"found\", \"her\", \"now\", \"go\", \"and\", \"get\", \"her\"],\n",
    "            [\"Remember\", \"to\", \"let\", \"her\", \"into\", \"your\", \"heart\"],\n",
    "            [\"Then\", \"you\", \"can\", \"start\", \"to\", \"make\", \"it\", \"better\"],\n",
    "            [\"So\", \"let\", \"it\", \"out\", \"and\", \"let\", \"it\", \"in\", \"hey\", \"Jude\", \"begin\"],\n",
    "            [\"You're\", \"waiting\", \"for\", \"someone\", \"to\", \"perform\", \"with\"],\n",
    "            [\"And\", \"don't\", \"you\", \"know\", \"that\", \"it's\", \"just\", \"you\", \"hey\", \"Jude\", \"you'll\", \"do\"],\n",
    "            [\"The\", \"movement\", \"you\", \"need\", \"is\", \"on\", \"your\", \"shoulder\"],\n",
    "            [\"Hey\", \"Jude\", \"don't\", \"make\", \"it\", \"bad\"],\n",
    "            [\"Take\", \"a\", \"sad\", \"song\", \"and\", \"make\", \"it\", \"better\"],\n",
    "            [\"Remember\", \"to\", \"let\", \"her\", \"under\", \"your\", \"skin\"],\n",
    "            [\"Then\", \"you'll\", \"begin\", \"to\", \"make\", \"it\"],\n",
    "            [\"Better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"oh\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by doing some readability analysis. A Readability Index is the result a formula that evaluates the words and structure of a text and extracts its complexity level. \n",
    "\n",
    "In this exercise, we will the Coleman-Liau Index (CLI). It approximates the minimum school grade expected to understand the text. So, for instance, if the Coleman-Liau Index is 4.27, it means that the student should be at least in the 4th grade to understand it.\n",
    "\n",
    "The Formula for the index calcuation is the following:\n",
    "\n",
    "$ CLI = 0.0588L - 0.296S - 15.8 $\n",
    "\n",
    "where\n",
    "\n",
    "L = number of characters for every 100 words\n",
    "\n",
    "S = number of sentences for every 100 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Which is the approximate minimum school grade of a child to be able to understand the Hey Jude Lyrics?\n",
    "Use the Coleman-Liau Index formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coleman_liau_index(text):\n",
    "\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing your code\n",
    "hey_jude_cli = coleman_liau_index(hey_jude)\n",
    "print('The recommended school grade to understand \"Hey Jude\" lyrics is {}. (Should be between 2 and 3)'.format(hey_jude_cli))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the individual words. It is a common task for data scientists to analyze text and extract information from it. We can use lots of sophisticated tools to analyze it using NLP techniques (Natural Language Processing), but in this exercise we will do a much simpler analysis. For every analysis that we will be doing, consider the following:\n",
    "\n",
    "* We should ignore text case. So \"Jude\" and \"jude\" should be considered the same word\n",
    "* Some words and tokens we must ignore. These words and tokens are far too meaningless to be considered. They are called stop_words. Here is a list of stop words to be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['a', 'to', 'it', 'and', 'his', 'nah', 'the', 'you', 'your', 'her', 'be']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Let's create a function that counts words. It receives a text list (similar to the hey_jude above) and a stop word list. It should return a dict, containing the word count.\n",
    "\n",
    "So, if someone calls\n",
    "\n",
    "```\n",
    "word_count([[\"Hey\", \",\", \"Jude\"],\n",
    "            [\"don't\", \"be\", \"afraid\", \",\", \"jude\"]], [\"be\", \",\"])\n",
    "```\n",
    "It should return a dict, like this:\n",
    "```\n",
    "{\"hey\": 1,\n",
    " \"jude\": 2,\n",
    " \"don't\": 1,\n",
    " \"afraid\": 1}\n",
    "```\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here goes your code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing your code\n",
    "word_count_test = word_count(text=[[\"Hey\", \",\", \"Jude\"],\n",
    "                                   [\"don't\", \"be\", \"afraid\", \",\", \"jude\"]],\n",
    "                             stop_words=[\"be\", \",\"])\n",
    "\n",
    "\n",
    "print('The word \"Jude\" appears {} times (should be 2)'.format(word_count_test.get('jude', 0)))\n",
    "print('Does the stop word \"be\" appear in the word_count? : {} (should be False)'.format(\"be\" in word_count_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Which word is the most frequent in hey_jude? How many times does it appear?\n",
    "Write some code that evaluates the result of word_count on hey_jude and prints the requested information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_frequency(dict_count_words):\n",
    "    \n",
    "    #your code\n",
    "            \n",
    " \n",
    "\n",
    "print('The most frequent word \"{0[0]}\" appears {0[1]} times.'.format(top_frequency(word_count(hey_jude, stop_words))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Which words appear only once in hey_jude? How many are they?\n",
    "Write some code that evaluates the result of word_count on hey_jude and prints the requested information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_frequency(dict_count, count):\n",
    "    result = []\n",
    "    \n",
    "    #your code\n",
    "            \n",
    "    return # your code\n",
    "\n",
    "word_list = # your code\n",
    "\n",
    "print('There are {} Words that apear once:\\n'.format(len(word_list)))\n",
    "print(*word_list, sep = ', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another frequent type of analysis that Data Scientists execute on text is something called sentiment analysis. The goal of sentiment analysis is to evaluate a piece of text and determines if the overall feeling is something positive or negative. It is useful to evaluate social media posts for example (is this tweet a positive one? Or negative one?) and product reviews. This can get very complex, but we will do something simple. \n",
    "\n",
    "\n",
    "Consider the set W as the set of unique words in our text (ignoring the stop words).\n",
    "\n",
    "\n",
    "$ sentiment = \\frac{\\sum_{w \\in W} weight(w) * count(w)}{\\sum_{w \\in W} count(w)} $\n",
    "\n",
    "count(w) can be obtained from the word_count function that you implemented before.\n",
    "\n",
    "weight(w) can be obtained from the following dict, where\n",
    "\n",
    "$ weight(w) \\in [-1.0, +1.0] $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_weights =   {'bad':       -1.00,\n",
    "                  'sad':       -0.90,\n",
    "                  'pain':      -0.85,\n",
    "                  'fool':      -0.50,\n",
    "                  'shoulders': -0.40,\n",
    "                  'colder':    -0.30,\n",
    "                  'refrain':   -0.10,\n",
    "                  'under':     -0.10,\n",
    "                  'begin':     +0.10,\n",
    "                  'start':     +0.10,\n",
    "                  'cool':      +0.50,\n",
    "                  'better':    +1.00}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a word does not exist in the above dict, it is considered neutral (it is neither positive or negative).\n",
    "\n",
    "#### 2.5 Let's start by creating a function that calculates the sentiment. Then, we proceed to evaluate Hey Jude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_sentiment(word_counts, weights):   \n",
    "\n",
    "   # your code here\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test your code\n",
    "test_sentiment = average_sentiment({'bad': 1, 'begin': 1, 'start': 2, 'better': 1, 'jude': 1}, word_weights)\n",
    "print(\"The average sentiment of this test is {} (should be bwtween 0.05 and 0.06)\".format(test_sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.6 What is the overall sentiment of Hey Jude? Is it positive or negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code should print the answers\n",
    "# Example outcome: \"Overall sentiment of Hey Jude: 0.2089 then it is positive \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.7 What is the sentiment of the first 4 sentences of Hey Jude? Is it positive or negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code should print the answers\n",
    "# possible outcome: \"Sentiment of first 4 sentences of Hey Jude: 0.0400, it is positive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.8 What is the sentiment of the last 5 sentences of Hey Jude? Is it more positive than the first 4 sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code should print the answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. IBOV stats\n",
    "\n",
    "In this exercise we will do some quick analysis on the Bovespa Index. Our dataset will be the closing values for the IBOV index during a period of 100 days.\n",
    "\n",
    "You can do the analysis by calculating it yourself or using python modules - it is your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibov = [60148.26,60720.9,61015.09,62056.47,60108.72,59988.1,60771.79,59647.32,59420.86,57434.37,\n",
    "        57199.14,56869.02,58042.87,59997.64,59505.17,57630.35,55609.07,56470.59,57542.49,57017.55,\n",
    "        56584.4,54720.25,54502.97,54573.18,55138.35,54244.03,53326.54,53638.69,55377.15,55934.69,\n",
    "        55850.13,54477.25,54358.7,55519.24,56382.22,55680.41,55162.14,54404.41,53527.01,51408.54,\n",
    "        51939.6,50717.97,48435.3,49633.16,51270.4,52392.86,48416.33,49228.92,45908.51,48422.75,\n",
    "        53055.38,51540.58,49593.17,49842.99,51828.46,50782.99,46028.06,49541.27,49798.65,46145.1,\n",
    "        44517.32,42100.79,40139.85,38593.54,37080.3,35609.54,40829.13,41569.03,36833.02,36441.72,\n",
    "        36399.09,39441.08,39043.39,35069.73,33818.49,31481.55,29435.11,33386.65,34845.21,37448.77,\n",
    "        37256.84,38249.44,40254.8,37785.66,36361.91,36665.11,36776.27,37261.9,34373.99,35993.33,\n",
    "        35789.1,35717.21,34094.66,33404.55,31250.6,34188.83,34812.86,36469.61,36212.65,36595.87]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some of the exercises it will be more useful if you, instead of looking at the absolute IBOV values, look at the variations between the days (gains and losses). I will do this calculation for you, but it is your call to decide when to use the original dataset and when to use the variations dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is not the best way to do this calculation, but we want to keep it simple\n",
    "# if you can think of a better way of doing it, go ahead!\n",
    "ibov_delta = [ibov[x] - ibov[x-1] for x in range(1, len(ibov))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 Plot charts with the values of both data series. This will make your life easier, since you will have a better understanding of the data\n",
    "*Tip: use matplotlib*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting original set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting delta values for Ibov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 This is a very special dataset - it is the IBOV values during the 2008 financial market crisis.  Compare two periods: the first 50 days and the last 50 days. Which period has higher volatility (higher volatility = the values are changing a lot)\n",
    "Please, write code to justify your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the measures of how spread out are the values is something called IQR (Inter Quartile Range). It measures the Range between the Quartiles Q3 and Q1.\n",
    "\n",
    "$ IQR = Q3 - Q1 $\n",
    "\n",
    "One classical way of checking for the existence of Outliers (points that are exceptionally high or exceptionally low for a dataset) is to use the IQR to calculate some boundaries:\n",
    "\n",
    "$ lower = Q1 - 1.5 * IQR $\n",
    "\n",
    "$ upper = Q3 + 1.5 * IQR $\n",
    "\n",
    "An outlier is a value higher than the upper bound or lower than the lower bound.\n",
    "\n",
    "### 3.3 By using this definition of Outlier (based on IQR), do you see any outliers in the data series?\n",
    "*Tip: remember that we have two data series*\n",
    "\n",
    "Please, write code to justify your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.1 - Outliers for Ibov Index values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot outliers for ibov Index\n",
    "import statistics as s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2 - Ouliers for Delta Ibov Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot outliers for Delta Ibov Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is impossible to predict the exact times when to buy or sell stocks. The ideal is, of course, to buy the stocks when the price is the lowest and sell it when it is the highest.\n",
    "\n",
    "#### 3.3 Consider the IBOV values during this period. What is the highest percentual gain that someone could obtain by buying and selling the stocks at the best times (1 buy operation and 1 sell operation)\n",
    "Suppose that the stock that you are trading follows exactly the IBOV index\n",
    "\n",
    "*Tip: you cannot sell before you buy, so maybe this exercise is not that trivial as it appears*\n",
    "\n",
    "Please, write code to justify your answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here you can use plot or numbers to justify your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using Matrices and Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next exercises, we will be using matrices to deal with sales data. \n",
    "\n",
    "We will be using numpy. If you don't have numpy installed, maybe now it is a good time to install it.\n",
    "\n",
    "Consider that the company that I work for sells 3 products to 4 customers. In a given month, we can represent the sales by using a Matrix: every row in the matrix will be a customer and every column represents a product. Every cell in this matrix represents the amount of every product sold. \n",
    "\n",
    "Here is our example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sales = np.matrix([[1, 3, 4],\n",
    "                   [2, 1, 5],\n",
    "                   [0, 2, 4],\n",
    "                   [4, 2, 1]])\n",
    "\n",
    "products = np.matrix([['Bread', 'Cheese', 'Jam']])\n",
    "\n",
    "customers = np.matrix([['John'], \n",
    "                       ['Paul'],\n",
    "                       ['Ringo'],\n",
    "                       ['George']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the 3rd row of the matrix represents the 3rd customer - Ringo. The 2nd column of the matrix represents our 2nd product - Cheese. By using this conventions, we can see that in this particular month Ringo has bought 2 units of Cheese.\n",
    "\n",
    "Suppose our products are sold by the following prices, in dollars:\n",
    "\n",
    "(yes, we know that The Beatles were from th UK... :-) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = np.array([1.20, 2.12, 0.99])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can start to calculate sales data based on these vectors by using operations with matrices. Please, use numpy and matrix operations to solve the questions below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 How many units of Jam were sold this month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 How many units of products were bought by Paul (the total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 How many dollars were spent by Ringo in each Product: (the answer should be an array or a 1-column matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4 I want to show to my boss a detailed report of how many dollars each customer spent. Could you help me by providing this information (the answer will be a matrix with just 1 column. First line of the column will be the John's total. Second will be Paul's, and so on...)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 What is the total sales amount in dollars for this month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.6 My boss asked for a simulation: if we had increased \\$0.10 in all prices, what would be our total sales in dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.7 My boss is not satisifed with the previous result! He wants an additional increase of 20% in all prices, after the \\$0.10 increased on the previous question. What would be our total sales in dollars then? Can you provide a detailed matrix of how much every person would have paid in total for each product in dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Exercises\n",
    "These Exercises are Optional, but we encourage you to try it. Some of the concepts used here will be explored during the hands on training and by solving these exercises you will feel more comfortable and prepared.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using regression to predict house prices\n",
    "We will be using a popular dataset for this exercise. It contains data about House Sales in King County, USA (where Seattle is located).\n",
    "\n",
    "The data can be downloaded from [Kaggle](https://www.kaggle.com/harlfoxem/housesalesprediction).\n",
    "\n",
    "You can choose which python modules you want to use to analyze the data (the one you are most comfortable with). \n",
    "\n",
    "*Tip: If you don't know where to start, we recommend using pandas and scikit-learn.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1 Visualize and Explore the data\n",
    "Start by making some exploration of the data. Plot charts (the ones you think are meaningful for this scenario) and explain the general trends and insights you have just by analyzing the data visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.1 Load and Overview of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.2 - Overall Analysis of House Sales data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use plot and/or sckitlearn models for a linear regression if you please\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write here your insights\n",
    "\n",
    "* ...\n",
    "* ...\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2 Split the dataset in two datasets: training data and test data\n",
    "It is a best practice while working with regressions and Machine Learning in general to have separate datasets to train your model and to test it. One will be used to fit your regression (or create your model) and the other one will be used to test your regression (or your model). We will use 80% of the data to fit the regression and 20% of the data will be reserved to test the model.\n",
    "\n",
    "*Important: this must be a random split!! Flush the data before performing the split*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3 Simple Linear Regression - sqft_living\n",
    "Let's start by fitting a model using the variable that instinctively makes more sense for a regression: sqft_living (it is the area of the living space of the house).\n",
    "\n",
    "* Fit a model using sqft_living as your variable and price as the target of the regression.\n",
    "* Plot a chart containing the data points and your fit. What do you think? Does the fit explains well the data?\n",
    "* Using this model, how much would cost a house with 2000 sqft?\n",
    "* What are the values of intercept and slope? How would you interpret these values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get series for training and evaluation \n",
    "\n",
    "#Fix shape of arrays according sklearn docs\n",
    "\n",
    "\n",
    "#Create regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit( # complete with your code)\n",
    "\n",
    "#Plot result\n",
    "\n",
    "\n",
    "print('With this model the price of a 2000 sqft house would be %.2f' %(regr.predict(2000)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considerations \n",
    "* ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4 Simple Linear Regression - trying with other variables\n",
    "Well, maybe sqft_living is not the best predicting variable. We should try using other variables.\n",
    "\n",
    "* Fit 3 regression models: one using bedrooms, other using bathrooms and other using sqft_lot\n",
    "* Which of these 3 models is the best predictor of house prices? How does it compare with the sqft_living model? (explain yourself)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1 - Bedrooms x Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2 - Bathrooms x Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3 -  Square Feet Lot  x Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Considering the 3 models  above write here your insights\n",
    "\n",
    "* ...\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5 Be creative! (optional)\n",
    "Consider yourself free to try other regression techniques. What would you do to have better predictions? Use other variables? Feature engineering? Regularization? Propose and implement a better approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### From my learning during this exam I think that those are some points for enhancements\n",
    "* ...\n",
    "* ...\n",
    "* ...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
